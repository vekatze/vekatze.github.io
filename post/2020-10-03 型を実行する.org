---
title: 型を実行する
published: 2020-10-03
updated: 2020-10-15
mathjax: on
---

#+OPTIONS: H:6

もともとは次をすべてみたすような言語を探していた：

1. 十分に強い型システムをもっている
2. 普通のλ計算でプログラムを書くことができる
3. メモリ管理が静的である

まあ我ながらワガママとしか言いようがない。これらすべてをクリアするものはなかなか見つからない。特に3つ目がきつい。最初の2つの条件だけなら単にGCと手をつなげばハッピーエンドであり、実際OCamlとかHaskellとかF#とかで私はたいへん満足なのだが、ここに最後の条件を入れた途端に話はぐっとむずかしくなる。

その後、なんだかんだで[[https://github.com/u2zv1wx/neut][結局自分で上記のような言語を書くに至った]]。依存型理論ベースであって、リソース管理のための追加のアノテーションが存在せず、かつメモリ管理が静的であるような言語である。で、実現にあたり、最後の条件をクリアするために考えついた手法がたぶん結構おもしろく、本稿はそれを紹介するものである。

オチを先取りして言うなら、当該の手法は「型を実行する」ような代物になっている。もうすこし正確には、型を、その型をもつ値を複製・破棄するための関数へと変換するようなものとなっている。私はGCもregion-basedな路線もあるいはすべてを手でやる路線もそれぞれに好きなんだけど、それはそれとして、今回の路線はひとつの可能性としてなかなかおもしろいものになったんじゃないかと思う。

あらかじめいくつか断っておく。

- 本稿に安全性の証明のたぐいは一切含まれていない。ズコーッという感じだが、気にせず話を続けると、無論私もそうした証明が添えられていたほうが100倍よいと思ってはいる。とはいえ時間的資源は有限であり、この省除はあれこれを天秤にかけた結果である。あくまでこういう手法が可能っぽいですよ〜という示唆程度のものとして、話半分に受け取ってもらえればと思う。
- 動機や背景などについての記述は煩雑を嫌って補遺に回した。つまり本論のほうは手法の要点を最速で書き下すことに焦点をしぼったものとなっている。裏を返して言えば、手法のおもしろみが補遺ありきのものとなっていることを了解されたい。
- 本稿はOCamlやHaskellなどの経験があれば一通り読めるようにしたつもりで、読めないようであれば私が悪い。
# - 私はこの話はアイデアさえつかんでしまえばあとはいくらでも細部を埋められる種類のものだと思っている。本稿があまり形式ばっていないのはそのためで、むしろ平易であることを目指してみた。

前置きが長くなった。いいかげん本論に入ることにする。話は所望の性質をもった小さな言語について考えるところから始まる。

** 目次
:PROPERTIES:
:TOC: :include siblings :depth 2 :ignore (this)
:ID: toc
:END:
:CONTENTS:
1. [[#線形性の力を借りる][線形性の力を借りる]]
  1. [[#変数がちょうど1回だけ使用されるような言語][変数がちょうど1回だけ使用されるような言語]]
  1. [[#線形性のもとでのリソース管理][線形性のもとでのリソース管理]]
  1. [[#非線形性を密輸入しよう][非線形性を密輸入しよう]]
1. [[#型を実行する][型を実行する]]
  1. [[#リソース管理の語彙を対象言語の内部に見る][リソース管理の語彙を対象言語の内部に見る]]
  1. [[#型がより具体的にどう変換されるか][型がより具体的にどう変換されるか]]
  1. [[#変換された型がどう利用されるか][変換された型がどう利用されるか]]
  1. [[#本論のおわりに][本論のおわりに]]
1. [[#補遺][補遺]]
  1. [[#自然演繹にすごい勢いで入門する][自然演繹にすごい勢いで入門する]]
  1. [[#証明論からくる動機][証明論からくる動機]]
  1. [[#局所完全性の計算論的意義][局所完全性の計算論的意義]]
  1. [[#複製破棄によるリソース管理を基礎づける][複製・破棄によるリソース管理を基礎づける]]
  1. [[#まともな性能を期待できるのか][まともな性能を期待できるのか]]
  1. [[#その他のあれこれ][その他のあれこれ]]
1. [[#跋][跋]]
:END:

** 線形性の力を借りる
*** 変数がちょうど1回だけ使用されるような言語
フル装備の言語のまえに簡単な部分言語について調べてみるというのは素直な発想だと言ってよいと思う。本稿もその方針でいく。

「簡単な部分言語」と一口に言っても、制限のしかたにはいろいろある。ここでは変数の使われ方に制限を入れる。より具体的には、OCamlとかHaskellのような言語であって、定義された変数がすべてちょうど1回だけ使用されるようなものを考える。こうした変数の使用はしばしば「線形である」といわれる[fn:linear]。

この言語を L^{-} とよぶことにしよう。たとえば次の疑似コードは言語 L^{-} においてコンパイルを通過するべきものである：
#+begin_src txt
let x := 100 in
let y := 1 in
add x y
#+end_src
変数 ~x~, ~y~ がどちらも線形に使用されていることに注目してほしい。他方で次の疑似コードはコンパイルエラーとなるべきものである：
#+begin_src txt
let x := 100 in
add x x
#+end_src
というのは、変数 ~x~ が ~add x x~ において2回使用されているからである。少なすぎてもだめで、たとえば
#+begin_src txt
let x := 100 in
10
#+end_src
は、 ~x~ が1回も使用されていないのでコンパイルエラーとなる。あるいは、 ~increment~ という関数がすでにどこかで定義されているとして、次の疑似コードもコンパイルエラーとなるべきものである：
#+begin_src txt
let x := 100 in
let y := increment x in
add x y
#+end_src
こちらでも変数 ~x~ が ~increment x~ と ~add x y~ において計2回使用されているのがわかると思う。いわば、 ~increment x~ において ~x~ はすでに消費されてしまっており、それゆえ ~add x y~ の時点ではもう ~x~ は利用できない、という具合である。

いちおう一言添えておくと、もちろんすべての変数に線形性を課すなんてのは制限として相当キツい部類のもので、実際の言語にこんな制約があればおよそ現実的なプログラムなど書けたものではない。が、我々はすぐあとでこの制約がどのようにして回避されるかを見る。というわけで表現能力の問題については特に心配はいらない。

*** 線形性のもとでのリソース管理
ここでは言語 L^{-} の構成要素は変数とλ抽象と関数適用と ~let~ のみであるとする。つまり、 ~[1, 2, 3]~ のような配列であるとか、あるいは上で見たような ~100~ のような整数であるとかは言語に含まれないものとしていったん無視しておく。というのは、これらを言語に追加するにしても、結局λ抽象について以下で述べることが実質的にそのまま機能するからである。ようは話が長くなるだけだからカットする。

# また、 ~let~ は実際にはλで表現可能なのだが、今ここに立ち入っても別にうれしくないのでこいつも言語の構成要素として入れておく。

このような言語 L^{-} において静的なリソース管理をおこなうことを考えてみる。つまりコンパイル時の情報だけでメモリをうまく割り当てることを考えてみる。すると、次のような自明な解決があることがわかる。

まず、メモリを割り当てるのは、λ抽象を処理するタイミングとし、またこのときだけとする。たとえば、
#+begin_src txt
let f := λ y. (なんかの計算) in
(つづきの計算)
#+end_src
のようなコードがあったとして、このコードの挙動は、
1. ~λ y. (なんかの計算)~ を表現するためのメモリ領域を割り当て、
2. その領域にλ抽象の情報を書き込み（これは ~(info-1, ..., info-n)~ のような組になり、クロージャともよばれる）、
3. その領域へのポインタを ~f~ に束縛して、
4. ~(つづきの計算)~ を実行する
という具合のものになる。この部分の処理については、言語が線形であろうがなかろうがたいした違いはない。メモリ領域を割り当てないことにはλ抽象の情報をメモリ上で表現できないのだから、当たり前といえば当たり前である。

他方、メモリを解放するのは、関数適用を処理するタイミングとし、またこのときだけとする。たとえば、
#+begin_src txt
(なんかの計算) in
f a
#+end_src
のようなコードがあったとして、このコードの挙動は、
1. ~(なんかの計算)~ をおこない、
2. 関数 ~f~ に束縛されているはずのλ抽象の情報 ~info-1~, ..., ~info-n~ をメモリ領域から取り出し、
3. 関数 ~f~ の外側の ~(info-1, ..., info-n)~ を解放し、
4. とりだしたλ抽象の情報のもと、 ~a~ を引数として目的の関数を呼び出す
という具合のものになる。

上記のように定めたメモリ解放は安全で、かつすべてのリソースを解放するのだが、これは言語の線形性からしたがう。すなわち、まず、線形性によって、λ抽象はすべてちょうど1回だけ使用される。これはもちろん、λ抽象がすべて1回以下使用され、かつ1回以上使用されるということである。1回以下使用（適用）されるのだから、任意のλ抽象に対して施されうる解放は1回以下である。つまり性質「解放したものを繰り返し解放してしまうことがない」が保証される。また、1回以上使用（適用）されるのだから、任意のλ抽象に対して施されうる解放は1回以上である。つまり性質「割り当てたものは必ず解放される」が保証される。

というわけで、言語 L^{-} においては上記の解釈によってメモリが安全かつ確実に解放される。静的なメモリ管理が実現できる。つまりは所望の性質がタダで得られる。次節では、このありがたい性質を保ちながら言語 L^{-} の表現能力を強めることを考える。つまり線形性に対する迂回路を用意することを目指す。

*** 非線形性を密輸入しよう
迂回するには抜け道があればよい。任意の型 ~A~ について、次のような定数を言語 L^{-} に追加してみる：
- ~copy_A : A -> A * A~
- ~discard_A : A -> top~
ここで ~A * A~ は2個の ~A~ 型の値からなるペアの型であり、また ~top~ というのはいわゆるunit型である。少し考えてみれば、これらがあれば変数の数についての制約は迂回できることがわかる。たとえば次のような違法なコードをとってみる：
#+begin_src txt
let x := 1 in
add x (add x x)
#+end_src
上記のコードは、上の定数を用いて、計算結果を保ちながら次のように書き換えてやることができる：
#+begin_src txt
let x := 1 in
let (x1, tmp) := copy_int x in
let (x2, x3) := copy_int tmp in
let (add1, add2) := copy_(int->int->int) add in
add1 x1 (add2 x2 x3)
#+end_src
そしてこのコードは言語 L^{-} のものとして合法である。あるいは
#+begin_src txt
let x := 100 in
10
#+end_src
という違法なコードについても同様で、こちらは
#+begin_src txt
let x := 100 in
let () := discard_int x in
10
#+end_src
とすれば済む。どちらの例においても、 ~copy_int~ および ~discard_int~ によって変数の使用が線形になるよううまく帳尻が合わせられていることに注目されたい。一般に、 ~A~ 型の変数 ~x~ がn回使用されているとして、
- n < 1ならば ~discard_A~ を用いることで ~x~ の使用を線形にすることができる。
- n = 1ならば ~x~ の使用はすでに線形である。
- n > 1ならば ~copy_A~ を用いることで ~x~ の使用を線形にすることができる。

それゆえ、線型性によって損なわれていた表現能力はこれらの定数によってとりもどされる。そして、ベースの言語には触れていないのだから、リソースについて奇妙な挙動を示しているのはこれらの定数だけである。というわけで、あとはこれらの定数の中身が具体的にどのようなものになるべきであるかを考えてやればよい[fn:modal]。

# これでようやく本題に入ることができる。次節ではこの定数を具体的にどう実現するかを見る。

** 型を実行する
冒頭で先取りして述べた通り、リソース管理のための情報はすでに型のうちにある。本節では、まず型をリソース管理に利用するにあたってのアイデアを示し、次にそのアイデアのもとでより具体的にさまざまな型がどのように上記の ~copy_A~ / ~discard_A~ を実現するかを見て、最後に型の変換結果がどのように利用されるかを見る。

*** リソース管理の語彙を対象言語の内部に見る
コアとなるアイデアを例で示す。いま、 =e= という =A * B= 型のtermがあるとする。このときわれわれは、 =e= が具体的にどのような内部構造をもっているかを知ることなく、その型情報のみによって、 =e= を次のように展開することができる：
#+begin_src txt
let (x, y) := e in (x, y)
#+end_src
こうした展開はしばしばη展開とよばれるもので、 =e= にあたるtermが副作用をもたないかぎりにおいて、termの意味を保つ：
#+begin_src txt
   let (x, y) := ("foo", (3, true)) in (x, y)
~> ("foo", (3, true))
#+end_src
# ここで「 =~>= 」は「簡約すると」（評価すると / 実行すると）の意である。展開後のtermが展開前のtermへと簡約されていることに注目されたい。

さて、ポイントは、 =e= がどんなものであるかによらず、型の情報だけからこの展開をおこなうことができるという点である。これはすなわち、η展開の操作をひとつの関数として書きうるということでもある。つまり次のような関数を =A * B= に対応するη展開としてとることができる：
#+begin_src txt
λ z.
  let (x, y) := z in
  (x, y)
#+end_src
この関数のなにが嬉しいかって、 ~e~ の中身であるところの ~x~ および ~y~ が変数として参照可能になるところ、つまり ~e~ の中身をたどれるようになるところである。いま、このη展開を参考に、型に対してその型をもつtermの中身をたどる関数を対応づけるような変換が仮に定義できるとして、それを ~Expand(_)~ と書くことにすると、 ~Expand(A * B)~ は、
#+begin_src txt
λ z.
  let (x, y) := z in
  let x' := Expand(A) x in
  let y' := Expand(B) y in
  (x', y')
#+end_src
のようになるだろう。他の型に対してもこの ~Expand(_)~ を具体的に定めてゆけばtermを再帰的にたどれそうである。

もちろん、 ~Expand(_)~ が定義できたとしても、それだけではη展開をterm全体にいわば伝播させることが可能になっただけで、リソースの複製・破棄についての議論はまだ絡んでこない。だがそれらは実は既にほとんど解決ずみである。実際たとえば、すべての型に対して複製関数を対応付けるような変換が仮に定義できるとして、それを ~Copy(_)~ と書くとき、 ~Copy(A * B)~ は
#+begin_src txt
λ z.
  let (x, y) := z in
  let (x1, x2) := Copy(A) x in
  let (y1, y2) := Copy(B) y in
  ((x1, y1), (x2, y2))
#+end_src
のように定めてやれる。これはたしかに ~A * B -> (A * B) * (A * B)~ という型をもっている。あるいはまた、すべての型に対して破棄関数を対応づけるような変換が定義できるとして、それを ~Discard(_)~ と書くとき、 ~Discard(A * B)~ は、
#+begin_src txt
λ z.
  let (x, y) := z in
  let () := Discard(A) x in
  let () := Discard(B) y in
  ()
#+end_src
としてやればよい。これもたしかに ~A * B -> top~ という型をもっている。

ようするに、 ~copy_A~ および ~discard_A~ は、展開を関数として再帰的に表現したものを「n乗」へと拡張することで実現できそうに見える、というのがコアのアイデアである。型に対してこのような計算論的解釈を与えられるのではないか、という話である。そしてこのように定数を定義できるのであれば、型 ~A~ を定数のペア ~(copy_A, discard_A)~ へと変換してやれば、対象言語のほうでこのペアから必要なほうを適宜とりだして使用することで前節で見たような帳尻合わせが可能になるのではないか、という話である。そしてそれを実装しましたよ（証明はないけど！）、というのが冒頭に示したリポジトリである。

なお実際には、型 ~A~ は、 ~copy_A~ と ~discard_A~ のペアではなく、次のような2引数関数 ~exp_A~ へと変換されることになる：
#+begin_src txt
λ flag z.
  if flag
  then discard_A z
  else copy_A z
#+end_src
この ~exp_A~ は次のように使用される：
#+begin_src txt
-- x : Aをdiscardしたいとき
let () := exp_A true x in
(...)

-- x : Aをcopyしたいとき
let (x1, x2) := exp_A false x in
(...)
#+end_src
これは表現能力云々の話ではなく、純粋に実装上の最適化である。これによって、型は（ペアではなく）閉じた静的な関数へと変換されることになる。そして閉じた関数はLLVMのレベルではただの関数ポインタとして、つまり普通の即値と同じように複製・破棄できるから、結局、型の変換結果はふつうの即値と同じように複製・破棄できるということになる。ペアで実装していたならば発生していたであろう面倒なallocation/freeの処理をパスすることができ、かつ実行効率の向上も期待できるという具合であり、それゆえ実装ではこちらの方針をとることにした。

*** 型がより具体的にどう変換されるか
ここでは複製・破棄の関数がより具体的にいろいろな型に対してどのように定められるかを見てみる。

**** 即値
~int~ のような、即値の型について。これについては次のようにして ~copy~ と ~discard~ を定めてやればよい：
#+begin_src txt
let copy_int :=
  λ x. (x, x)

let discard_int :=
  λ x. ()
#+end_src
~copy_int~, ~discard_int~ が受けとる引数は即値であり、それゆえ特にメモリにふれることなく複製・破棄できる。ゆえに非線形に複製・破棄してやればよい。これらの関数におけるメモリにかかわる操作は、 ~(x, x)~ のための領域の確保だけである。

**** 配列
~int[3]~ のような、配列の型について（配列の中身は即値であるとしておく）。これについては次のようにして ~copy~ と ~discard~ を定めてやればよい：
#+begin_src txt
let copy_int_3 :=
  λ x.
    let [a, b, c] := x in
    ([a, b, c], [a, b, c])

let discard_int_3 :=
  λ x.
    let [a, b, c] := x in
    ()
#+end_src
つまり、まず ~x~ から中身をとりだしたうえで、その中身をつかって新たな配列をつくればよい。ここで、
#+begin_src txt
let [a, b, c] := x in (...)
#+end_src
においては、
1. ~x~ のそれぞれの要素を ~a~, ~b~, ~c~ に束縛し、
2. 配列 ~x~ をfreeする
という挙動が想定されている。というわけで、たとえばcopyのほうの挙動は、
1. ~x~ のそれぞれの要素が ~a~, ~b~, ~c~ に束縛される
2. ~x~ が解放される
3. ~[a, b, c]~ のためのメモリ領域をわりあてる (1回目)
4. ~[a, b, c]~ を新たに構成してメモリ領域に書き込む (1回目)
5. ~[a, b, c]~ のためのメモリ領域をわりあてる (2回目)
6. ~[a, b, c]~ を新たに構成してメモリ領域に書き込む (2回目)
7. ~([a, b, c], [a, b, c])~ のためのメモリ領域をわりあてる
8. ~([a, b, c], [a, b, c])~ をメモリ領域に書き込む
といった具合になる。 ~a~, ~b~, ~c~ が即値なのでタダでコピーできていることに注意。あるいはまた、discardのほうの挙動は、
1. ~x~ のそれぞれの要素が ~a~, ~b~, ~c~ に束縛される
2. ~x~ が解放される
という具合になる。 ~a~, ~b~, ~c~ が即値なのでタダで破棄できていることに注意。

**** 型の型
~A : Type~ と書くときの ~Type~ もまた型であり、それゆえ変換されるべきものである。が、上でみたように、 ~A : Type~ のとき、 ~A~ は即値と同様に処理できるのであった。というわけで、
#+begin_src txt
let copy_type :=
  λ x. (x, x)

let discard_type :=
  λ x. ()
#+end_src
として終了である。

**** 関数の型
~int -> bool~ のような、関数の型の変換について。これはやや複雑なので、大意をつかみたいだけであれば読み飛ばしてもらっても構わないかもしれない。なんにせよ、この部分の説明にはまず（型ではなく）λ抽象がどのように変換されるのかについてふれる必要がある。次のようなコードを考えてみる：
#+begin_src txt
let f :=
  let b := true in
  let y := 10 in
  λ x. x + (as-int b) + y in
(...)
#+end_src
なお、 ~as-int~ は、（なんでもよいが、たとえば） ~true~ を ~1~ に、 ~false~ を ~0~ にそれぞれうつすような関数であるとする。

さて上記のコードには、 ~λ x. x + (as-int b) + y~ という、自由変数として ~b : bool~ および ~y : int~ をもつλ抽象が含まれている。こうしたλ抽象は、通常のプログラミング言語においては、ふつう
#+begin_src txt
((b, y),
  λ (x, env).
    let (b, y) := env in
    x + (as-int b) + y)
#+end_src
というペアへと、つまり、
#+begin_src txt
({自由変数のあつまり},
 λ (もとの引数, env).
   let (自由変数だったものたちの名前) := env in
   {もとのコード})
#+end_src
というペアへと変換される（クロージャ変換）。さて、今回の体系では、ここの処理を次のように拡張する。すなわちλ抽象を次のような3要素のtupleへと変換する：
#+begin_src txt
(bool * int,
 (b, y),
  λ (x, env).
    let (b, y) := env in
    x + (as-int b) + y)
#+end_src
つまり自由変数についての型の情報を添える[fn:closedchain]。ここまでくればもうクロージャの複製・破棄の方法はほとんど明らかである。実際、3つの要素のそれぞれの複製・破棄について、
- ~bool * int~ の型は ~Type~ であるので、これは即値として複製・破棄ができる。
- ~(b, y)~ については、第1成分の ~bool * int~ を利用すれば複製・破棄ができる。
- 関数部分については、これは閉じた関数なので普通の関数ポインタに落とせて、ゆえに即値として複製・破棄ができる。
こうしてクロージャの複製・破棄が実現される[fn:depcls]。

型のほうの話に戻れば、結局、 ~int -> bool~ のような関数の型の ~copy~ / ~discard~ は、 ~int~ とか ~bool~ とかによらず
#+begin_src txt
let copy_closure :=
  λ cls.
    let (env_type, env, func) := cls in
    let (env1, env2) := env_type false env in
    ((env_type, env1, func), (env_type, env2, func))

let discard_closure :=
  λ cls.
    let (env_type, env, func) := cls in
    let () := env_type true env in
    ()
#+end_src
となる。なおここで、
#+begin_src txt
let (x1, ..., xn) := x in (...)
#+end_src
においては、
1. ~x~ のそれぞれの要素を ~x1~, ..., ~xn~ に束縛し、
2. tuple ~x~ をfreeする
という挙動が想定されている。

# **** ペア
# ペアのケースについて。実はこのケースは正確には「型の変換の様子」としては不適格で、というのは、ペアはクロージャのケースに帰着されるからである（そういう実装方針をとってあるからである）。つまり、ユーザが書く言語において、ペアのための型 ~A * B~ は組み込みの型として存在するものではない。そうではなく、λで実装されるものになっている。それゆえクロージャについての議論によってペアは実現される。

# とはいえ、これだけではあまりにあんまりであるので、帰着の様子についてもうすこしきちんと述べておく。ペアのための型 ~A * B~ を利用するためには、その型の定義と、その型の値を作る方法と、その型の値を使う方法のそれぞれがあればよい。まず型の定義であるが、これは
# #+begin_src txt
# A * B := forall (z : Type). (A -> B -> z) -> z
# #+end_src
# となる。値をつくる方法であるが、これは、 ~a : A~, ~b : B~ であるとして、 ~(a, b)~ を
# #+begin_src txt
# λ (z : Type)
#   λ (k : A -> B -> z).
#     k a b
# #+end_src
# によって定める。値を利用する方法であるが、これは、 ~let (a, b) := e in (...)~ を、 ~(...)~ の型が ~C~ であるとして、
# #+begin_src txt
# e C (λ a b. (...))
# #+end_src
# によって定めればよい。ちなみにこれはChurch encodingとよばれる常套手段の一例になっている。

*** 変換された型がどう利用されるか
最後に、上記のように型が変換できたとして、このときユーザの書いた関数のなかの変数がどのように線形化されるのかを見てみる。たとえば次のような関数があるとする：
#+begin_src txt
let to-pair :=
  λ (A : Type) (x : A). (x, x)
#+end_src
この ~to-pair~ という関数は次のように使用されることを意図したものである：
#+begin_src txt
to-pair int         3             # ~> (3, 3)
to-pair string      "hello"       # ~> ("hello", "hello")
to-pair (bool * top) (false, unit) # ~> ((false, unit), (false, unit))
#+end_src
つまり ~to-pair~ は多相的な関数であり、受け取った引数をペアにして返すようなものである（ちなみに ~int~ とか ~string~ とかの部分は実際には推論で省略できる）。

# ベースの型システムを依存型にしていることもあって、Haskellなどの場合と異なり、 ~int~ や ~string~ などの型が引数として通常のtermとまったく同じようにして ~to-pair~ に与えられているのが目を引くかもしれない（もちろんこの部分は推論によって適宜省略できるが）。

さて、すぐに見てわかるように、上記 ~to-pair~ の定義においては変数 ~x~ が2回、つまり線形でない仕方で使用されている。この非線形な ~x~ は、型 ~A~ の変換結果を用いて、次のように線形化される：
#+begin_src txt
let to-pair :=
  λ A x.
    let (x1, x2) := A false x in
    (x1, x2)
#+end_src
つまり、 ~to-pair~ は、たしかにさまざまなサイズをもった値を引数 ~x~ の位置に受け取るのだが、それに付随する型 ~A~ のほうに ~x~ を複製するにあたって必要な情報がつねに入ってくるので、 ~to-pair~ は ~x~ がどんなものであれ複製することができる。discardについても同様で、このような型情報があればうまくいきそうであることがみてとれると思う。

*** 本論のおわりに
以上で本論は終わり。型が実行され、静的なリソース管理が実現された。多分にスケッチ的ではあるが。

ここまで読んでもらえたなら、実装にあたって依存型を選ぶことになった理由もなんとなく察してもらえるのではないかと思う。つまり、型がふつうのtermと同じように出現してくれるので、たんに実装がラクなのである。

そういえば、依存型理論のうれしさを紹介するにあたって私が知っている記事ってほとんど全部くらいの勢いで長さつき配列の例を示しているんだけど（配列の型に長さの情報を付与すれば安全に配列の要素にアクセスできるよ、みたいなやつ）、私は依存型理論のうれしさって、むしろ言語の見通しがよくなるところ、一貫性が高まるところにあるんじゃねえかなあと思っていたりする。ベースの論理体系が依存型になっていると、型についての抽象もふつうの関数もどちらもただのλに落ちてくれるわけで、まあわかりやすい。型の定義のために特別な構文が必要になったりもしない。

というか依存型理論ってよくつらいつらい言われてるけど別にそうでもないと思うんだよな。型推論が決定不能になるよ～ってのも、そりゃ理論のレベルではそうだろうけど、普通にプログラムを書くぶんにはよっぽど変なことでもしないかぎり (System F を派手に逸脱するようなものを書かないかぎり) すげえ普通に推論できるし。そしてだいたいのプログラムってSystem Fの枠内でわりとハッピーに書けるし。推論がめっちゃ遅くなるわけでもないし。まあいいか。

ついでにここでひとつ断っておこう。私はこの型を関数に変換する手法はいちおう新しいものだと思って本稿を書いている。が、往々にして世の中には似たようなことを考えているえらい先駆者がいるものである。同じようなことを書いている人が既にいたなら、そのとき本稿は先人にささげるひとつの注釈であるだろう。

以下は補遺である。こちらを読むと、たぶん、本論がセオリーを知ったあとの格ゲーのようにおもしろくなる。ぜひどうぞ。

** 補遺
*** 自然演繹にすごい勢いで入門する
最初は省略することも考えたのだけど、やはり説明上どうにも外せなかった。というわけで自然演繹の入門（超特急）を添える。よりちゃんとした入門記事としては、たとえば[[https://www.cs.cmu.edu/~fp/courses/15317-f09/schedule.html][Pfenningの講義資料]]がよいのではないかと思う。タダで読める。ありがてえ。

**** 命題論理ことはじめ

まず互いに区別のつく記号のあつまりをひとつ固定して、この集合の要素を命題変数とよぶことにする。命題変数は自然数と同じ数だけあるとする。そのうえで、命題を次のように定める。
1. \( \alpha \) が命題変数であるならば、 \( \alpha \) は命題である。
2. \( A, B \) が命題であるならば、 \( A \to B \) は命題である。
3. 以上によって命題となるものだけが命題である。
たとえば \( P, Q, R \) が命題変数であるとき、 \( P \), \( P \to Q \) などは命題であるし、 \( P \to (Q \to R) \), \( (P \to P) \to R \) などもまた命題である。

あるいはもしかすると、ここで「\( P \to (Q \to R) \)の "\( ( \)" と "\( ) \)" ってなんだよ」と思う向きがあるかもしれない。そんなに気にしなくてもよいところではあるが、いちおうこの疑問に答えておく。これらのカッコは、たんに \( P \to Q \to R \) と書いただけでは、
#+begin_src txt
    →
   / \
  →   R
 / \
P   Q
#+end_src
なのか、それとも
#+begin_src txt
  →
 / \
P   →
   / \
  Q   R
#+end_src
なのかの区別がつかないので、そこを明示するためのメタな記号である。木構造っていう二次元的なものを文章っていう一次元的な環境で表現するにあたっての道具であって、最初から上記のような木構造を毎回書くと決めていればこのカッコは不要になる。でもそれだといちいち場所をとってだるい。なのでカッコを利用して書いてしまいましょうね、という話。整理すると、
1. 「\( A \to B \) は命題である」と書いてあるときの「\( A \to B \)」は上記のような木構造である
2. でも木構造をいちいち展開して書くのはだるい
3. ところで文章のほうでもカッコをつかえば木構造をうまく表現できる
4. ならカッコつかって書けばよくね
という具合である。カッコを利用しているのはあくまで表現上の都合で、そこで表現されているものは木構造である。

あともうひとつ、最後の条件「以上によって命題となるものだけが命題である」がすこし奇妙に見えるかもしれない。が、これもたいしたことはなくて、たんに、たとえば「じゃあ \( P \uparrow \uparrow \downarrow \downarrow \leftarrow \to \leftarrow \to  Q \) とか ~墨染の君が袂は雲なれや絶えず涙の雨とのみ降る~ とかは命題なんですか」と尋ねられたときにきちんとNoと答えられるようにするためのものにすぎない。最後の条件がないと、なにが命題であるかはわかるが、なにが命題でないかはわからないということになってしまう。

命題については終わり。こんどは「準文脈」を次のように定める。
1. \( \cdot \) は準文脈である。
2. \( \Gamma \) が準文脈であり、かつ、 \( A \) が命題であるとき、\( \Gamma, A \) は準文脈である。
3. 以上によって準文脈となるものだけが準文脈である。
ようするに準文脈とは命題の列である。 \( \cdot, A, B, C \) みたいなやつ。あるいは同じことだが、露骨に書けば、
#+begin_src txt
      ,
     / \
    ,   C
   / \
  ,   B
 / \
.   A
#+end_src
みたいなやつである。命題の場合とちがってカッコの出番がないのは、なんでもよいが、たとえば
#+begin_src txt
      ,
     / \
    ,   C
   / \
  A   ,
     / \
    .   B
#+end_src
のような木構造が準文脈の定義からしてそもそも存在せず、それゆえ区別の必要がないことによる。 \( \cdot, A, B, C \) を準文脈として書けばそれで木構造がただひとつに決まることによる。

\( \cdot \) を空の準文脈とよぶことにする。上の例からもわかるように、空でない準文脈は \( \cdot, A_1, \ldots, A_n \) というかたちをしているわけだが、これはふつう冒頭の \( \cdot \) を省略して \( A_1, \ldots, A_n \) と書かれる。

順序を無視した準文脈を「文脈」と呼ぶことにする。\( A, B, C, C \) と \( C, B, A, C \) は、準文脈としては異なるが、文脈としては同一である。

上記の準備のもと、「判断」を次のように定める。
1. \( \Gamma \) が文脈であり、かつ \( A \) が命題であるとき、記号 \( \Gamma \vdash A \) は判断である。
2. 以上によって判断となるものだけが判断である。
たとえば \( A \vdash A \) とか \( C \vdash A \to (B \to B) \) とか \( \cdot \vdash ((A \to B) \to A) \to A \) とかはすべて判断である。

さて、「判断」とかいうあからさまな名前が与えられているとはいえ、これは今の段階ではまだ特定の記号のパターン、特定の形をした木構造にすぎない。先取りして言うなら、「\( \Gamma \vdash A \)」を「\( \Gamma \)を仮定したとき \( A \) は正しい」と解釈できるようにしたいのだが、まだそうした解釈を可能にするための枠組みがない。

というわけで、次にこの「判断」なるものに対して「この判断は正しい」とか「正しくない」とか言えるようにするための枠組みを定めていく。いわば、われわれは判断の意味について語るための枠組みを定めるのである。

一般に言って、記号の意味を定めるにあたってはおおむねふたつの路線がある。

1. 内的な路線。この路線では記号がなにを指示するかを定める。記号「あのリンゴ」に対して、あの机の上に置いてある赤い物体を対応づけるような路線である。これはいわば記号の中身に注目する路線である。指示対象（＝意味）が定められていれば、たとえば「あのリンゴ」によって藤原定家が指示されているとき、それは記号の指示対象（＝意味）として正しくないと判定することができる。
2. 外的な路線。この路線では記号がどう使用されるかを定める。記号「あのリンゴ」に対して、それを聞いた者にあの机の上に置いてある赤い物体に意識を向けさせる、という用法を割り当てるような路線である。これはいわば記号の振る舞いに注目する路線である。用法（＝意味）が定められていれば、たとえば「あのリンゴ」という言明を聞いた者が突然フォックストロットの練習を始めたとき、それは記号の用法（＝意味）として正しくないと判定することができる。

判断の意味づけにあたり、ここでとるのは後者の路線である。つまり判断という記号がどのような仕方で使用されうるものであるのかをいくつかの規則によって定めていく。このような、判断の用法を定める規則のことを推論規則とよぶ。

まず推論規則それ自体についての説明が必要だろう。推論規則は一般に次のような形で表現される：

\[
\require{bussproofs}
\begin{prooftree}
  \AxiomC{\( \mathcal{J}_1 \hspace{1em} \ldots \hspace{1em} \mathcal{J}_n \)}
  \RightLabel{\( \mathsf{(name)} \)}
  \UnaryInfC{\( \mathcal{J} \)}
\end{prooftree}
\]

横棒の上にくる \( \mathcal{J}_i \) が、前提となる判断である（\( \mathcal{J} \) は "Judgement" の "J"）。これらの前提がすべてそろっているとき、横棒を書いてその下に結論としての新たな判断 \( \mathcal{J} \) を書いてよい、とするのが推論規則であり、\( \mathsf{(name)} \) はその規則の名前である。

さて規則を追加していこう。まずは変数についての規則である：

\[
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( (\mathsf{var}) \)}
  \UnaryInfC{\( \Gamma, A \vdash A \)}
\end{prooftree}
\]

これは前提として必要な判断が0個であるような規則で、それゆえ横棒の上が空白になっている。キブンとしては、「\( A \) が仮定されているならば、 \( A \) は正しい。 \( \Gamma \) を追加で仮定しても同じことである」のように読まれるべきものである。もうすこし正確に言うと、上記の推論規則を認めることによって、「\( \vdash \)」がわれわれの「ならば」の類比物として読まれるべきものとなる。

いくつか例を示しておこう。以下はすべて規則 \( \mathsf{(var)} \) の正当な適用である：

\[
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( B, A \vdash A \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A \vdash A \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A, B, C, D \vdash A \)}
\end{prooftree}
\]

他方で以下はすべて規則 \( \mathsf{(var)} \) の正当でない適用である：

\[
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A, C \vdash B \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A \vdash A \to A \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( \cdot \vdash A \)}
\end{prooftree}
\]

さて次の規則にうつる。次は、「\( \vdash \)」の意味を命題のほうの「\( \to \)」に埋め込むものである。

\[
\begin{prooftree}
  \AxiomC{\( \Gamma, A \vdash B \)}
  \RightLabel{\( (\to_{\mathsf{i}}) \)}
  \UnaryInfC{\( \Gamma \vdash A \to B \)}
\end{prooftree}
\]

これはキブンとしては、「「\( \Gamma \) かつ \( A \)」 ならば \( B \) が成立しているとき、\( \Gamma \) ならば 「\( A \to B \)」が成立する」と読まれるべきものである。われわれはすぐ直前で規則 \( \mathsf{(var)} \) によって、「\( \vdash \)」の意味を「ならば」として、あるいは少なくとも「ならば」と読みうるものとして定めたのだった。ひるがえって、こちらの推論規則は、こうした判断のレベルでの「ならば」を、命題のレベルの 「\( \to \)」 という記号に落としこむものになっている。

# このような「判断のほうに意味を定めておいて、それを論理結合子のレベルに落としこむ」という論法はたぶんけっこう重要で、本稿ではふれないが、たとえば[[https://www.cs.cmu.edu/~fp/papers/mscs00.pdf][様相演算子をもつような自然演繹をデザインするときなんかにもつかえるアイデアとなっている]]。
# 論理結合子を与えるのは判断の形式である。

ところで、上記の規則は論理結合子「\( \to \)」を含んだ命題を新たに作りだすものになっている。すなわちこの規則は、どういった条件のもとで特定のかたちをした命題を言いうるのかを定めるものであり、こうした推論規則は導入則 (introduction rule) とよばれる。逆に、特定のかたちをした命題からどういったことが言いうるのかを定めるものもあり、こちらの推論規則は除去則 (elimination rule) とよばれる。「\( \to \)」の除去則は次のようになる：

\[
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash A \to B \)}
  \AxiomC{\( \Gamma \vdash A \)}
  \RightLabel{\( (\to_{\mathsf{e}}) \)}
  \BinaryInfC{\( \Gamma \vdash B \)}
\end{prooftree}
\]

これはようは「\( \to \)」として表現された「ならば」を使う方法を与えるものである。「\( A \) ならば \( B \)」と「\( A \)」とが分かっているときに「\( B \)」を導出してよいとするものであり、特にこれといってびっくりするようなことはないはずである。

推論規則としてはとりあえず以上の3つ、つまり、
1. 変数の規則
2. 「ならば」の導入則
3. 「ならば」の除去則
をとっておく。望むならANDとかORとかも追加できるが、話が無駄に長くなるので控えておく。

ここまでに定めた推論規則を繰り返し適用することにより、たとえば次のような記号のパターンを生成することができる：

\[
\begin{prooftree}
  \AxiomC{\( \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( B, B, A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( B, B \vdash A \to A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( B \vdash B \to (A \to A) \)}
  \AxiomC{\( \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( B \vdash B \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( B \vdash A \to A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \cdot \vdash B \to (A \to A) \)}
\end{prooftree}
\]

こうして生成される記号のパターンのことを証明図あるいは単に証明とよぶ。

**** 証明図にある回り道
ある判断 \( \Gamma \vdash A \) を導出するにあたっても、いろいろな証明図がありうる。たとえば \( \cdot \vdash A \to A \) の証明について考えてみる。もちろんこれには

\[
\begin{prooftree}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \cdot \vdash A \to A \)}
\end{prooftree}
\]

という素直な証明があるが、他方で、次のような冗長な証明もありうる：

\[
\begin{prooftree}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A, A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( A \vdash A \to A \)}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \cdot \vdash A \to A \)}
\end{prooftree}
\]

こちらも同じ \( \cdot \vdash A \to A \) を証明しているが、にもかかわらず証明図が無駄にデカい。

ここで次のように問うてみよう。すなわち、このデカさはどこに由来しているのだろうか。上記の証明図はなぜ無駄にデカくなっているのだろうか。結論から言えば、それは、上記の証明図が「回り道」を含んでいるからである。ここで言う「回り道」は、具体的には次の部分である：

\[
\begin{prooftree}
  \AxiomC{\( A, A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( A \vdash A \to A \)}
  \AxiomC{\( A \vdash A \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( A \vdash A \)}
\end{prooftree}
\]

ここでは論理結合子「\( \to \)」が導入され、さらにこれがすぐさま除去されている。しかし導入してすぐに除去するくらいであれば、最初から導入しなければよいのではないか。このような意味において、上記は「回り道」、証明図を余計にデカくするものである。こうした「回り道」は、より一般には、次のような形をしている：

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H}_1 \)}
  \UnaryInfC{\( \Gamma, A \vdash B \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \Gamma \vdash A \to B \)}
  \AxiomC{\( \mathcal{H}_2 \)}
  \UnaryInfC{\( \Gamma \vdash A \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( \Gamma \vdash B \)}
\end{prooftree}
\]

すなわち「回り道」とは、「ある論理結合子を導入して、すぐさまその論理結合子を除去する」ようなパターンである（ここで、 \( \mathcal{H}_1, \mathcal{H}_2 \) は「上につづく証明図」をひとつの記号で表現したものである）。こうした「回り道」は簡約基ともよばれる。

ここで、一般的なほうの簡約基を5分ほどグッとにらむと次のようなことがわかる。すなわち、上記のように簡約基を含んだ証明図があるとき、 \( \Gamma \vdash B \) の証明であって簡約基をなくしたものを作ることができる。これには次のようにすればよい。まず

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H}_1 \)}
  \UnaryInfC{\( \Gamma, A \vdash B \)}
\end{prooftree}
\]

の部分に注目する。いま、この \( \mathcal{H}_1 \) のどこかで \( \Gamma, A \vdash B \) の文脈にある \( A \) が使用されているとする。このとき、この \( A \) の代わりに、

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H}_2 \)}
  \UnaryInfC{\( \Gamma \vdash A \)}
\end{prooftree}
\]

由来の \( A \) を用いるようにしてやる。こうすれば \( \Gamma, A \vdash B \) のほうの \( A \) には出る幕がなくなる。これはすなわち、 \( \Gamma, A \vdash B \) の文脈の中にある \( A \) がなくとも \( B \) が証明できるということである。すなわち、\( \mathcal{H'}_1 \) を、 \( \mathcal{H}_1 \) に対して

1. 仮定にあった \( A \) の代わりに \( \mathcal{H}_2 \) 由来の \( A \) を用いるようにする
2. 仮定の \( A \) を消去する

という書き換えをおこなって得られる証明図であるとすれば、

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H'}_1 \)}
  \UnaryInfC{\( \Gamma \vdash B \)}
\end{prooftree}
\]

が導出可能であるということである。この書き換えは次のようにまとめられる：

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H}_1 \)}
  \UnaryInfC{\( \Gamma, A \vdash B \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \Gamma \vdash A \to B \)}
  \AxiomC{\( \mathcal{H}_2 \)}
  \UnaryInfC{\( \Gamma \vdash A \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( \Gamma \vdash B \)}
\end{prooftree}
\hspace{3em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( {\mathcal{H'}_1} \)}
  \UnaryInfC{\( \Gamma \vdash B \)}
\end{prooftree}
\]

このような、簡約基を打ち消す書き換えのことを簡約とよぶ。証明図を簡約しつづけて簡約の余地のない証明図を得ることを正規化とよぶ。

**** 証明図を簡約する / プログラムを実行する

前節では \( \mathcal{H} \) という記号で証明木を表わしていた。ここでは前節よりもローカルな仕方で証明木の情報を保持することを考えてみる。つまり、推論規則を適用するたびに、その適用した推論規則のログを残すようにしてみる。そのログを見ればそこまでにどういった推論規則の適用があったのかを判別できるようにするのである。まず、変数の規則をもういちど見てみる：

\[
\begin{prooftree}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( \Gamma, A \vdash A \)}
\end{prooftree}
\]

ここでどのような推論をおこなったのかのログを判断に埋め込みたい。そのためには、たとえば

\[
\begin{prooftree}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( A, A \vdash A \)}
\end{prooftree}
\]

という推論において、文脈の \( A \) のうちどちらが使用されているのかを区別できていなければならない（でないとその情報が失われてしまう）。そこで、文脈のそれぞれの命題に名前を与えることにする。具体的には次のようにする。まず、自然数と同じ数だけの要素からなる集合をとり、これを変数集合と呼ぶことにする。また変数集合の元のことを変数と呼ぶことにする。そのうえで、準文脈の定義を次のように拡張する。

1. \( \cdot \) は準文脈である。
2. \( \Gamma \) が準文脈であり、かつ、 \( x \) が変数であり、かつ、 \( A \) が命題であるとき、記号 \( \Gamma, x : A \) は準文脈である。
3. 以上によって準文脈となるものだけが準文脈である。

さらにまた、次のように「証明項」を定義する。これを用いて証明のログを記録していくことになる。
1. \( x \) が変数であるとき、 \( x \) は証明項である。
2. \( x \) が変数で、かつ \( e \) が証明項であるとき、 \( \lambda x. e \) は証明項である。
3. \( e_1 \), \( e_2 \) が証明項であるとき、 \( e_1 \mathbin{@} e_2 \) は証明項である。
4. 以上によって証明項となるものだけが証明項である。

この証明項を用いて、判断の定義を次のように拡張する。

1. \( \Gamma \) が文脈であり、 \( e \) が証明項であり、 \( A \) が命題であるとき、記号 \( \Gamma \vdash e : A \) は判断である。
2. 以上によって判断となるものだけが判断である。

これで規則 \( \mathsf{(var)} \) を拡張するための準備がととのった。先に \( A, A \vdash A \) の例がどのように変わるかを示したほうがわかりやすいだろう：

\[
\begin{prooftree}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( x : A, y : A \vdash y : A \)}
\end{prooftree}
\]

つまり文脈のそれぞれの命題に \( x \) や \( y \) といった名前が与えられたことによって、どちらの命題が規則 \( \mathsf{(var)} \) において使用されたのかの情報を保持できるようになる。推論規則としては、

\[
\begin{prooftree}
  \AxiomC{\(  \)}
  \RightLabel{\( \mathsf{(var)} \)}
  \UnaryInfC{\( \Gamma, x : A \vdash x : A \)}
\end{prooftree}
\]

となる。判断 \( \Gamma \vdash e : A \) における証明項 \( e \) の部分に、その判断がどのようにして導出されたのかについてのログ情報が入ってくる。

「\( \to \)」の導入則にうつろう。こちらは次のように拡張される：

\[
\begin{prooftree}
  \AxiomC{\( \Gamma, x : A \vdash e : B \)}
  \RightLabel{\( (\to_{\mathsf{i}}) \)}
  \UnaryInfC{\( \Gamma \vdash \lambda x. e : A \to B \)}
\end{prooftree}
\]

仮定が \( \Gamma, x : A \vdash e : B \) となっているのはたんに判断の定義が拡張されたからで、特におどろくべきところはない。また、結論のほうに出てくる証明項が \( \lambda x. e \) という「いかにも」な代物になっているが、これはたんに「\( \to \)」の導入則を変数 \( x \) に注目して適用したということ（＝証明のログ）を記録しているにすぎない。こうした推論規則の拡張はまったくもってオートマティックであり、特に創意工夫が絡んできたりするところではない。

そして最後に「\( \to \)」の除去則を見る。こちらは次のように拡張される。

\[
\newcommand{\app}[2]{#1 \mathbin{@} #2}
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e_1 : A \to B \)}
  \AxiomC{\( \Gamma \vdash e_2 : A \)}
  \RightLabel{\( (\to_{\mathsf{e}}) \)}
  \BinaryInfC{\( \Gamma \vdash \app{e_1}{e_2} : B \)}
\end{prooftree}
\]

こちらもたんに証明項がわりあてられているというだけの話で、特におどろくべきところはない。

さて、ここでさきほどの簡約基に証明項をわりあてることを考えてみる。すると次のような証明図が得られる：

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H}_1 \)}
  \UnaryInfC{\( \Gamma, x : A \vdash e_1 : B \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \Gamma \vdash \lambda x. e_1 :  A \to B \)}
  \AxiomC{\( \mathcal{H}_2 \)}
  \UnaryInfC{\( \Gamma \vdash e_2 : A \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( \Gamma \vdash \app{(\lambda x. e_1)}{e_2} : B \)}
\end{prooftree}
\]

なんだかそれっぽい雰囲気が出てきたが、そしらぬ顔で話を続けてみる。簡約基をなくす操作についてもういちど考えてみる。これは結局、\( \mathcal{H}_1 \) に出現する \( x : A \) の使用を \( e_2 : A \) で代替するという操作である。つまり、簡約結果のほうの証明項は、 \( e_1 \) の中に出現するすべての \( x \) を \( e_2 \) で置き換えたものになる。これはすなわち、

\[
\begin{prooftree}
  \AxiomC{\( \mathcal{H}_1 \)}
  \UnaryInfC{\( \Gamma, x : A \vdash e_1 : B \)}
  \RightLabel{\( (\to_\mathsf{i}) \)}
  \UnaryInfC{\( \Gamma \vdash \lambda x. e_1 :  A \to B \)}
  \AxiomC{\( \mathcal{H}_2 \)}
  \UnaryInfC{\( \Gamma \vdash e_2 : A \)}
  \RightLabel{\( (\to_\mathsf{e}) \)}
  \BinaryInfC{\( \Gamma \vdash \app{(\lambda x. e_1)}{e_2} : B \)}
\end{prooftree}
\hspace{3em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( {\mathcal{H'}_1} \)}
  \UnaryInfC{\( \Gamma \vdash e_1 \{x := e_2\} : B \)}
\end{prooftree}
\]

ということである。ここで \( \{x := e_2\} \) は変数 \( x \) の出現を証明項 \( e_2 \) で置き換えるという代入の操作で、細かな定義は話が長くなるので省略する。 \( x + y + x \) を \( e_2 + y + e_2 \) に置き換えるような代物で、まあだいたい気合で想像できると思うので、適宜気合で想像しておいてほしい。

そして最後に、上記の簡約における証明項のふるまいについてだけ注目すれば、次のような（見慣れた？）規則が得られる：

\[
  \app{(\lambda x. e_1)}{e_2} \leadsto e_1 \{x := e_2\}
\]

というわけで、証明図を調べていた我々は、いつのまにかλ計算に、ひいてはプログラムにたどりついた。ひるがえって、証明項をプログラムであるとみなせば、今度は、判断 \( x_1 : A_1, \ldots, x_n : A_n \vdash e : A \) は「自由変数 \( x_1 : A_1, \ldots, x_n : A_n \) のもと、プログラム \( e \) は \( A \) という型をもつ」という型判断として読まれることになる。特に、ついさっきまで命題として解釈されていたものが、今度は型として解釈されることになる。こうして、たとえば証明図における回り道を解消することはプログラムを実行することに対応し、また回り道をどういう順番で解消していくかがプログラムをどういう戦略で実行していくか（名前呼び、値呼びなど）に対応し、などなど、と話が続いていくことになる。

こうした証明とプログラムとの対応関係はしばしばカリーハワード同型対応などとよばれる。「ならば」の分析からスタートして、証明について議論していたはずが、実際には同時にプログラムについての議論も進めていたことになる、という具合である。

証明の言葉をつかえるようになると、見通しもよくなるし啓発的だし、なにより楽しい。たとえば自然演繹のほうの議論を拡張して「〜は正しい」だけでなく「〜は必然的である」という語彙を追加してやって、で、こいつをプログラムのほうにうつすと[[https://www.cs.cmu.edu/~fp/papers/popl96.pdf][多段階計算（lispのquasiquoteみたいなやつ）に相当するものが引き出せたりする]]。

ちなみに上記のような、証明のほうで作った概念（たとえば必然性の様相）のプログラム側の対応物（たとえば多段階計算）をしばしば計算論的解釈という。「必然性（にもいろいろあるが、そのうちのひとつ）の計算論的解釈は多段階計算である」、みたいな。

*** 証明論からくる動機
**** 証明論でやっていこう
……と、ここまでが普通のカリーハワード同型対応の紹介である。だが本稿ではこの話に続きがある。いや、実際、私はけっこう感動したのだ、初めてカリーハワード同型対応を知ったとき。それで嬉々として、「よし、じゃあ試しに、同型対応をそのまま利用したような、あらゆる計算に証明論的な背景がひかえているような言語を書いてみよう」と思い立っていろいろ考えてみた。

変数はプログラミング言語のほうに簡単にうつせる。ならばの導入則もいい。除去則もよろしい。あれこれの他の論理結合子もノリで追加できる。不動点演算子も追加できて、はいチューリング完全。多相性も自然演繹のほうを命題論理から述語論理のちょっと弱いバージョンに拡張してやることで実現できて、型推論もよくある手法でふつうに実装できて、いいじゃん、いけるじゃん、と勢いづくわけだけど、ここでふと気付く。「……これメモリどうやって管理すんの？」

証明との対応がつきそうな既存の言語を調べてみる。どうやらGCを利用しているようである（OCaml, Haskell, F#, Idris, Coq, Agda, Lean）。なるほど。しかし今現在はカリーハワードに注目しているのであり、ならば証明の言葉でメモリも管理したいというのが人情である。いや人情であるかは知らんが、少なくとも私の感情ではあった。でもそういう言語は見つからなかった。

結局、上にあるような、プログラムを証明と同等のものとみなしうるという謳い文句はたしかに部分的には本当であるのだけど、少なくとも普通のλ計算をベースの言語とするかぎりにおいて、リソースについての議論は同型対応を逸脱するイレギュラーなものとして、実装上の工夫によって解決されるべきものとして処理されているようであった。なかなかうまくいかないものである。

**** regionでよくないかしら
さらにリソースの管理方式について調べていくとregion-basedな路線に出会うことになる。これは型システムにアノテーションを加えることでメモリ管理のための情報をとるという路線である。なるほどクールな路線ではある。メモリ管理も静的になるし、変な仕方でメモリを使用していた場合にはそれをコンパイル時に検出できたりもするし。

けれども私は強欲で、話をもっと証明に寄せたいと思ってしまうのである。直観主義の自然演繹を逸脱するようなアノテーションを利用するのは避けたい。プログラミング言語のほうに「証明論っぽくない」™、実装ありきのものを入れるのではなく、いつもの自然演繹の内部にリソース管理のための語彙を認めたい。「証明について考えていたらプログラムが出てくる」の図式をメモリについても維持したい。だから、現在の関心のもとでは、region-basedな体系をそのまま受け入れることはできない。別な関心のもとでは超便利であるとはいえ。

おそらく、ここでregion推論とよばれる手法についても検討してみるべきだろう。これは普通の型推論の拡張であって、型を推論するのと同時にregionを --- メモリ管理のための情報を --- 推論するものである。この手法のもと、たとえばStandard MLというOCamlによく似た言語（言語仕様）のコンパイラであって、静的にメモリを割り当てる/解放するようなものが[[https://sourceforge.net/projects/mlkit/][開発されていたりする]][fn:reginf]。

これはすなわち、特に追加のアノテーションを書くことなしに、直観主義の範囲で書かれたプログラムに対してそのメモリについての挙動を静的に定めてやれるということである。ならばこれで全部オッケーなのではないか。推論つきのregion-based memory management, これこそが顧客が本当に必要だったものなのではないか。

これに対しての応答は、次のような、型アノテーションが省略されたプログラムについて考えてみるところから始まる：

#+begin_src txt
λx. (not x, 10)
#+end_src

上記のλ抽象の型を推論するにあたり、ふつうコンパイラは ~x~ の型をいったん不明であるとし、そこに型変数を挿入するだろう。つまり、型変数を ~?M~ と書くとして、

#+begin_src txt
λ(x : ?M). (not x, 10)
#+end_src

のようなtermをつくるだろう。そのうえで型推論をおこない、 ~not : bool -> bool~ のような情報を利用して、 ~bool = ?M~ のような制約がつくられる。そうしてこれが解かれ、 ~?M = bool~ という置換が得られる。そしてこれをもとのtermに適用することによって、

#+begin_src txt
λ(x : bool). (not x, 10)
#+end_src

のようなtermがつくられる。それゆえもとのユーザのプログラムはこちらのプログラムの略記であったということになる。ここで注目すべきは、上記のプログラムに対してまさに上記のような仕方で ~?M~ という穴が与えられたのは、ひとえにその型推論の定義によるという点である。もし仮に、（なんでもいいが）たとえばこの型推論において変数の使用回数についての情報も取得したいのであれば、コンパイラは

#+begin_src txt
λ(x : <?M, ?n>). (not x, 10)
#+end_src

といった具合のtermを作ることになり、これが解かれて

#+begin_src txt
λ(x : <bool, 1>). (not x, 10)
#+end_src

のようなtermが得られ、それゆえもとのユーザのプログラムは今度はこちらの略記であったということになる。というわけで、ユーザが書いたプログラムがどのような略記であるかは、ひいてはその略記を展開した姿は、型推論に相対的である。

さて、region推論は型推論の一種である。それゆえ、こうした推論をおこなう言語においてユーザが書くプログラムもまた、region推論に沿った略記ということになる。もっと言えば、region推論をおこなう言語において書かれるプログラムは、ちょうど上記の ~?n~ のようにして、型だけでなくregionについての省略も含んだものとなる。「本当は具体的にregionについての情報も書けるんだけど省略してある」という具合である。

というわけで、region推論をおこなう言語において直観主義の範囲で閉じているように見えるプログラムを書いてみせたところで、それはつまるところregionについての記述が省略された -- けれども推論結果としてそこにある -- プログラムだということになる。推論の仕方を変えた時点で、もとのプログラムがどのような略記であるかが変化している。それゆえ結局、region推論をおこなうケースは、最初からregionを型システムにもっている言語についての議論に帰着される。なのでregion推論による路線もまた、（何度も強調しているようにそれ自体はイケているが）現在の関心からして満足のいくものではない。

**** 動機と位置づけ
このようにして次のようなワガママな思いが浮かびあがってくる。つまり、ベースの言語をよくある自然演繹のものとして、証明論の言葉でメモリを管理することはできないのだろうか。λ計算に追加のアノテーションを与えることなしに、そもそものもとの言語のなかにリソース管理の情報を見つけだすことでメモリを管理できないだろうか。カリーハワード同型対応はプログラムの簡約についての説明を与えてくれるわけだが、ここにメモリについての説明も見つけられないか。

そしてこうした観点からすると、本稿はこの思いに対して肯定的に答え、さらに具体的にどのようにしてリソース管理を実現するかを示し、また同時にその実装も与えるものとなっている。「それができりゃあ苦労しないよ」と言われそうな与太話の「それ」を実現するようなものになっている。……苦労しなくなるのかどうかは謎だが。

こうしてようやく本稿に動機と位置づけが与えられる。長かった。

ところで、本論で見たように、リソース管理のための情報は実は命題＝型のうちにあるのであり、しかもそれはη展開とかいういかにも証明論めいたものを経由して利用されるのであった。しかしそれにしても、なぜη展開なのだろうか？ どうしてη展開について考えることがリソースについて考えることに絡んでくるのだろうか？ 次節ではこの点についてふれる。

*** 局所完全性の計算論的意義
**** 局所健全性
いったん証明論のほうに話を引き戻そう[fn:judgmental]。さきほど、証明図における回り道を消去するものとしての簡約をみた。ここについてもうすこし詳しく調べてみる。いま、たとえば「かつ」を論理結合子として目下の体系に組み込みたいとする。\( A \) と \( B \) との「かつ」を「\( A \land B \)」と書くとして、「\( \land \)」の導入則と除去則はどうなるべきか。

いや、まあ、導入則と除去則を書き下すことそのものは別にむずかしくない。導入則はたとえば次のようになるだろう：

\[
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e_1 : A \)}
  \AxiomC{\( \Gamma \vdash e_2 : B \)}
  \BinaryInfC{\( \Gamma \vdash (e_1, e_2) : A \land B \)}
\end{prooftree}
\]

つまり、\( A \land B \) が言えるためには、\( A \) と \( B \) とがともに言えていなければならない。当たり前といえば当たり前である。除去則も特にむずかしくなくて、選択の余地はあるが、たとえば次のようなものがとれる：

\[
\newcommand{\andlet}[3]{\mathsf{let}\, #1 := #2\, \mathsf{in}\, #3}
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{L}\, e : A \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}\, e : B \)}
\end{prooftree}
\]

どうでもいいが、ここで \( \pi \) は "projection" の "p" の意である。

この論理結合子の簡約は次のようになるだろう：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_1 : A \)}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_2 : B \)}
  \BinaryInfC{\( \Gamma \vdash (e_1, e_2) : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{L}(e_1, e_2) : A \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_1 : A \)}
\end{prooftree}
\]

\( \pi_\mathsf{R} \) のほうについても同様であろう：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_1 : A \)}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_2 : B \)}
  \BinaryInfC{\( \Gamma \vdash (e_1, e_2) : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(e_1, e_2) : A \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_2 : B \)}
\end{prooftree}
\]

ここまでは特に問題ないと思う。

さてここで悪魔に魂を売って、「\( \land \)」の導入則を次の2つに置き換えることを考えてみる。

\[
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e : B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{R}\, e : A \land B \)}
\end{prooftree}
\]

まあ見るからにヤバい。なんといっても、意味がわからない。実際、このような論理結合子があると、

\[
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(\mathsf{magic}_\mathsf{L}\, e) : B \)}
\end{prooftree}
\]

としてやるだけで、任意の命題 \( A \) から任意の命題 \( B \) が証明できてしまう。論理体系がぶっ壊れる。このような導入則と除去則の組み合わせを認めるわけにはいかないだろう。

なるほどこのとき「\( \land \)」は意味不明である。論理体系をぶっ壊すものである。上の実験からわかるのは、導入則と除去則のあいだにはなんらかの関係が成立していなければならず、そこが崩れていると論理体系をぶっ壊すような、およそ正気ではない、わけのわからない (unsoundな) 論理結合子ができあがってしまうということである。では、ひるがえって、ある論理結合子がまともなものであるためには、導入則と除去則のあいだにいったいどのような関係が成立していないといけないのだろう？

# なるほどこのとき「\( \land \)」は意味不明である。論理体系をぶっ壊すものである。それはそうなのだが、ここで次のように問うてみる。すなわち、上記のように導入則と除去則を定めたとき、なぜそれに対応する論理結合子は論理体系をぶっ壊すのだろうか？ 上の実験からわかるのは、導入則と除去則のあいだにはなんらかの関係が成立していなければならず、そこが崩れていると論理体系をぶっ壊すような、およそ正気ではない、わけのわからない (unsoundな) 論理結合子ができあがってしまうということである。では、ひるがえって、ある論理結合子がまともなものであるためには、導入則と除去則のあいだにいったいどのような関係が成立していないといけないのだろう？

試しに、「論理体系がぶっ壊れるからなんなの？ なんか問題ある？？」と開き直り、そのまま話を続けてみる。通常の「\( \land \)」のときと同じように、我々はこの気の狂った論理結合子に対しても簡約を定義しようとするだろう。簡約されるべき「回り道」は、この論理結合子については、導入則2つと除去則2つの組み合わせで次の4つのようになる：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{L}(\mathsf{magic}_\mathsf{L}\, e) : A \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(\mathsf{magic}_\mathsf{L}\, e) : B \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{R}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{L}(\mathsf{magic}_\mathsf{R}\, e) : A \)}
\end{prooftree}
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{R}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(\mathsf{magic}_\mathsf{R}\, e) : B \)}
\end{prooftree}
\]

これらのうち、まず1つ目のものについては次のように簡約が定められよう：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{L}(\mathsf{magic}_\mathsf{L}\, e) : A \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \)}
\end{prooftree}
\]

また4つ目のものについても次のようにすればよい：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{R}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(\mathsf{magic}_\mathsf{R}\, e) : B \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : B \)}
\end{prooftree}
\]

問題は2つ目のものと3つ目のものである。2つ目のほうを例にとる：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(\mathsf{magic}_\mathsf{L}\, e) : B \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{?} : B \)}
\end{prooftree}
\]

われわれは上記の回り道を打ち消すことができない。というのは、回り道を打ち消すためには、除去則の結論（ここでは\( B \)）を導入則の前提（ここでは\( A \)）だけをつかって示す必要があるわけだが、まさにそれが不可能であるためである。比較対象として、ここで通常の「\( \land \)」の簡約を見てみる：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_1 : A \)}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_2 : B \)}
  \BinaryInfC{\( \Gamma \vdash (e_1, e_2) : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{L}(e_1, e_2) : A \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e_1 : A \)}
\end{prooftree}
\]

ここでは確かに、除去則の結論としての「\( A \)」が、導入則の前提としての「\( A \)」および「\( B \)」だけを用いて証明されていることがわかる（今回はたまたま \( A \) しか使用されていないが）。

結局、回り道を打ち消す操作とは、除去則の結論を導入則の前提から証明するという操作である[fn:asm]。つまり、簡約が定義できるためには、導入則の結論を除去して得られうるすべての命題が、導入則の前提から証明できなけばならない。言い換えるなら、導入則に対し、除去則が強すぎてはいけない。 --- 除去則が強すぎると、導入則の前提でカバーできる範囲を逸脱した命題が得られてしまう。

通常の正気な「\( \land \)」の例で言えば、導入則の結論としての \( A \land B \) を除去して得られうるすべての命題（つまり \( A \) および \( B \) ）が、導入則の前提（つまり \( A \) および \( B \)）から証明できなければならない。そしてこの性質は満足されており、だからこそ「\( \land \)」の簡約が可能になっている。

他方、発狂した「\( \land \)」の例で言えば、導入則の結論としての \( A \land B \) を除去して得られうる命題 \( B \) は、 \( A \land B \) の導入則の前提が \( A \) であるとき、導入則の前提から証明することはできない：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{magic}_\mathsf{L}\, e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \pi_\mathsf{R}(\mathsf{magic}_\mathsf{L}\, e) : B \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{?} : B \)}
\end{prooftree}
\]

それゆえ簡約が定義できない。導入則に対して除去則が強すぎて、本当であれば言えないはずの \( B \) が言えてしまっている。

一般に、簡約の定義できる論理結合子は局所健全性 (local soundness) をもつという。局所健全性をもたないということは、ようするに本来言えないはずのことが言えるということである。あの発狂した論理結合子は、局所健全性をみたしていないがために論理体系をぶっ壊していた、と整理できよう。

**** 局所完全性
さて、こう整理すると、今度は局所健全性をひっくり返した性質について考えられるようになる。つまり「除去則が弱すぎない」という性質を考えられるようになる。こちらの性質は局所完全性とよばれる。

局所健全性のときは、けっきょく当該の性質を「簡約が定義できること」という証明図の書き換え可能性についての話に帰着できた。同様に、局所完全性についても、この性質を証明図の書き換え可能性によってとらえることができる。一般にやるとかえってわかりづらそうなので、ここでは \( A \land B \) を例にとって説明する。いま、 \( e : A \land B \) の証明図が得られているとする。結論から述べれば、このとき、
1. \( A \land B \) の証明図であって、
2. 前提として出現するものが \( e : A \land B \) だけであり、
3. すべての \( e : A \land B \) の出現に対してすぐさま除去則が適用されている
ような証明図を構成できるとき、「\( \land \)」は局所完全性をもっている、とする。もちろんここは「なんで？」となるところで、さっさとこれがどういう理屈にもとづいているのかを見ていこう。まず、上記の条件に沿った \( e : A \land B \) の書き換えとして次のようなものがとれる：

\[
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \land B \)}
\end{prooftree}
\hspace{1em}
\leadsto
\hspace{1em}
\begin{prooftree}
  \AxiomC{\( \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{left}\, e : A \)}
  \AxiomC{\(  \vdots \)}
  \UnaryInfC{\( \Gamma \vdash e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{right}\, e : B \)}
  \BinaryInfC{\( \Gamma \vdash (\mathsf{left}\, e, \mathsf{right}\, e) : A \land B \)}
\end{prooftree}
\]

この展開先の証明図について、確かに、

1. これが \( A \land B \) の証明図であること
2. 前提として出現するのが \( e : A \land B \) だけであること
3. すべての \( e : A \land B \) に対してすぐさま除去則が適用されていること

がわかると思う。

いま、仮に除去則が弱すぎたとする。このときは、「すべての \( A \land B \) がすぐさま除去される」という条件が存在することにより、\( A \land B \) の情報はいくらか欠損した形でしか利用できなくなる。それゆえもとの \( A \land B \) の証明を再構成することはできなくなる。たとえば \( A \land B \) の除去則から

\[
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash e : A \land B \)}
  \UnaryInfC{\( \Gamma \vdash \mathsf{right}\, e : B \)}
\end{prooftree}
\]

を削除したとする。このときは上記の書き換えの \( \mathsf{right}\, e : B \) の枝のほうが構成できず、ゆえに「\( A \land B \)」を取り戻すことはできない。それゆえこのとき「\( \land \)」は局所完全性をもたない（＝除去則が弱すぎる）。

逆に言えば、\( A \land B \) を取り戻せているという事実によって、\( A \land B \) の除去則が弱すぎないことがわかる。だから上記3点をみたすような展開が可能であることは「\( \land \)」の局所完全性の根拠になる。

**** 局所健全性と時間 / 局所完全性と空間
さて、一般に言って、プログラムの挙動について考えるとき、展開操作、つまり局所完全性に対応する証明論的な書き換えは、ぶっちゃけ影が薄い。なんならほとんど無視されるくらいの勢いであり、もっぱら簡約のほうにだけ注目されるのが常である。いや、「常である」は言いすぎだろうが、しかしそれくらいの雰囲気はある。特に、λ計算ベースのプログラミング言語の計算の挙動について考えるだけなら、簡約のほうにだけ注目すればそれで終了であり、展開には出る幕がない。

けど、それってわりと不思議であるような気もする。簡約のほうに注目している --- 簡約をプログラムとして勝手に便利に利用している --- のはヒトの都合で、いわば論理体系から見ればそんなことは知ったこっちゃないわけで、だったら展開が簡約と同じくらいの重要性をもっていてもよいのではないか、という気がしなくもない。なんせ裏返しなんだし[fn:adj]。このあたりから、展開にも簡約と同じくらい重要な役割があってもよいのではないか、という発想（妄想）が出てくる。

で、いま、あらためて考えてみると、簡約はまあプログラムの時間的なふるまいをつかさどるものである。でもって、時間の裏返しといえば、それはまあ計算機科学者に尋ねたならばまずは空間なのであり、このあたりから、展開は、局所完全性は、プログラムの空間的なふるまいをつかさどるものなのではないか、というアイデアが浮かんでくる。

そしてあらためて今回やったことをふりかえってみると、これはまさに展開を経由することでメモリの割り当てを、プログラムの空間的なふるまいを制御するものになっている。つまり今回の試行は、次のだいぶ危うげな対比にひとつの支えを与えるものとなっている：

- 局所健全性はプログラムの時間的なふるまいを基礎づけるものである
- 局所完全性はプログラムの空間的なふるまいを基礎づけるものである ← NEW!

……まあ私としても、ここがかなり妄言めいていることは承知している。「ΩΩΩ<な、なんだってー！？」である。とはいえ本稿の出どころがこのあたりにあったってのもまた事実で、だからひとつの記録として書き残しておくことにした。ブログ感。

*** 複製・破棄によるリソース管理を基礎づける
動機や位置づけについての話はここまでとしよう。ここでは本稿の手法のある側面に補足を与える。つまり、複製・破棄による路線にどのような根拠があるのかについて述べておく。

簡約のふるまいを観察してみるところから話は始まる。λ計算における次のようなごく普通の簡約を例にとる：
#+begin_src txt
   (λ x. (x, x)) @ "hello"
~> ("hello", "hello")
#+end_src
説明のため、この簡約における前後のtermに名前を与えておく：
#+begin_src txt
e1 := (λ x. (x, x)) @ "hello"
e2 := ("hello", "hello")
#+end_src
このとき上記の簡約はもちろん ~e1 ~> e2~ となる。

いま、GCを用いる純粋な言語において、ソースコードに ~e1~ というプログラムと ~e2~ というプログラムを書いたときの挙動を比較してみる。このとき、もちろん、上記の簡約に対応する計算がおこなわれるか否かにおいて、両者の挙動は異なったものになる。それはそうなのだが、しかし両者の差異はそれだけではない。すなわち次のような空間的な差異がある：

- ソースコードに ~e1~ を書いたときは、文字列 ~"hello"~ は一度作成されてしまえば ~(x, x)~ において共有される。つまり、 ~e1~ を簡約したあとの ~("hello", "hello")~ に相当する実行状態においては、第1成分と第2成分とが同一のメモリ領域（文字列 ~"hello"~ の先頭）を指示することになる。
- ソースコードに ~e2~ を書いたときは、文字列 ~"hello"~ は、その2回の出現に沿って素直に2回作成される。

~e1~ のほうでは文字列 ~"hello"~ は1つだけ作成されるのに対し、 ~e2~ のほうでは ~"hello"~ は2つ作成される。言い換えるなら、こうした実装の言語においては、 ~e1 ~> e2~ という簡約の前後どちらのtermをソースコードに書くかによって、プログラムの空間的挙動が異なったものになる。これはすなわち簡約が空間についての計算結果を保存していないということである。

では、β簡約が時間的な計算結果だけでなく空間的な計算結果も保存するよう要求してみるとどうなるか。このときには、 ~e1~ のほうにおいても ~e2~ と同じ数だけ文字列 ~"hello"~ が作成されなければなるまい。つまり2個である。そしてこの2というのはもちろん
#+begin_src txt
λ x. (x, x)
#+end_src
のλ抽象の中に出現している ~x~ の数であり、したがって ~e1~ の挙動は、call-by-valueで考えるとして、

1. まず引数 ~"hello"~ を評価するにあたってこれがメモリ領域に割り当てられ、
2. この文字列がλ抽象に渡され、
3. λ抽象のほうで変数 ~x~ の使用回数nに応じてこの文字列が複製あるいは破棄され、
4. そのうえで残りの処理をおこなう、

といったものにならざるをえない。そしてこのときはたしかに、 ~e1~ を実行したときにも ~"hello"~ はちょうど2つ作成されることになる。こうしてリソースの複製・破棄に背景が与えられる。つまり、簡約が時間についての計算結果だけでなく空間についての計算結果も保つよう要求したときに自然と必要となってくるのが複製・破棄の路線である。

*** まともな性能を期待できるのか
ところで、酔いのさめた頭で考えるとして、変数を使用するたびにいちいちコピーが発生するなんてのはまあ狂気の沙汰である。無駄どころの騒ぎではない。CPUの人権侵害である。では、複製・破棄のアプローチは象牙の塔でだけ通用する話であって、およそ非現実的な代物である、というのがオチになるのかというと、これは案外そうでもない。象牙の塔にも隠し扉くらいはある。最適化である。

というわけで以下で可能な最適化について3種類ほど書いていく。ここで一番おもしろいのはたぶん、それぞれの詳細よりもむしろ、これらリソースにかかわる性能云々の議論がすべてλ計算におけるtermの書き方についての議論に帰着されているという点である。既存のλ計算に手を加えることなしにその内部にリソース制御のための語彙をみつけている、ってところにアツさがある。

容易に予想されるとおりベンチとかはないので話半分に聞いてもらえればと思う。

# なんにせよ、3種類ほど、可能な最適化について書いてみる。基本は「非線形に変数を使ったときに複製・破棄が発生するなら、変数を線形に使えばいいじゃない」である。容易に予想されるとおり、ベンチとかはないので話半分に聞いてもらえればと思う。

**** 借用もどき
1つ目。freeされうるものを引数として受け取ったときは、それを返り値に含めましょう、という話。次のようなコードを考えてみる：
#+begin_src txt
let str := "hello" in
let _ := print str in
let _ := print str in
print str
#+end_src
上記は ~"hello"~ と3回出力するコードである。ここで注目するべきは、変数 ~str~ が3回使用されていることである。それゆえ上記のコードにおいては ~"hello"~ の3つのコピーが作成されることになる。だいぶつらい。

だが、この状況はちょっと考えてやれば回避できる。ポイントは ~print~ の型である。素朴にはこの型を ~string -> top~ のようなものにしたくなるところだが、そうではなくて、 ~string -> string * top~ とするのである。つまり ~print~ を、
1. 文字列 ~s~ を引数として受け取り、
2. ~s~ を出力し、
3. ~s~ と ~top.unit~ のペアを返す
という挙動のプリミティヴ関数として定める（このような ~print~ は ~s~ を2回使用しておきながらその複製をおこなわないというイレギュラーな挙動をもった関数、いわばズルであり、それゆえコンパイラ内部で定義される）。このような ~print~ を利用すれば、上記のコードは
#+begin_src txt
let str := "hello" in
let (str1, _) := print str in
let (str2, _) := print str1 in
print str2
#+end_src
あるいは同じことだが、変数名をそろえて
#+begin_src txt
let str := "hello" in
let (str, _) := print str in
let (str, _) := print str in
print str
#+end_src
と書き換えられる。これによって ~"hello"~ の出力にともなう複製は回避されることになる。

ちなみに上記のような、「引数として受け取ったものをそのまま返り値に同じ名前で含める」というのはどうやら頻出するパターンであるらしい。というわけで今回実装した言語においてはそれ専用の構文を用意してある。つまり、
#+begin_src txt
let _ := print &str in (...)
#+end_src
などと書くと、これは
#+begin_src txt
let (str, _) := print str in (...)
#+end_src
へとパース時点で書き換えられるようにしてある（実際の構文はS式ベースなので微妙に異なるが、本質的には上記の通りである）。借用もどきとでも言ったところか。あんまり借用とか言ってしまうとC++とかRustとかのやつと言葉が衝突して微妙なのでひかえたほうがよさそうだが。

なんにせよ、これを用いると、たとえば文字列を2回printするような関数は次のように定義されることになる：
#+begin_src txt
let print_twice :=
  λ str.
    let _ := print &str in
    let _ := print &str in
    (str, top.unit)
#+end_src

**** 状態とshadowing
2つ目。いま、われわれの言語において状態の絡んだ計算を表現したいとして、どういった方針をとるのがよいかを考えてみる。もちろんλ計算の力を使って、たとえばstateモナドを用いるという手はある。けれどもここには一つ難点がある。stateモナドにおける ~get~ が通常どのように実装されるかを見てみよう：
#+begin_src txt
let get :=
  λ s. (s, s)
#+end_src
ここで ~s~ の場所にくるのは状態である。たとえば ~string~ を状態としてもつようなstateモナドであれば、 ~s~ としては文字列が渡されることになる。こう見れば問題は明らかだろう。つまり、変数 ~s~ が ~get~ において非線形に（2回）使用されているため、 ~get~ を呼び出すたびに文字列のコピーが発生してしまうのである。状態を利用するたびに、状態がまるっとコピーされてしまう。これはさすがに悲劇である。できれば避けたい。というわけで、別な方法で状態を実現できないかと考えることになる。

そしてそうした「別な方法」は実際に存在する。端的に言って、トップレベルの変数に対して上で見たようなshadowingによる最適化をほどこせば済む。具体例を示すのがよいだろう：

#+begin_src txt
-- 状態を保持する変数を定義する
let str-state :=
  "hello" in

-- 状態sをうけとり、その状態のもとで計算をおこない、(更新された状態、top.unit)というペアを返す関数を定義する
let proc :=
  λ s.
    -- テキトーな計算
    let _ := print &s in
    let s := concat s "!" -- 現在の状態（文字列）の末尾に "!" を追加する
    let _ := print &s in
    (s, top.unit) in

-- トップレベルでさきほどの借用もどきを利用する
let _ := proc &str-state in
-- 上記は let (str-state, _) := proc str-state と同じもので、だからこの時点でstr-stateは "hello!" になっている

-- もう一回利用してみる
let _ := proc &str-state in
-- この時点でstr-stateは "hello!!" になっている

(...)
#+end_src

という具合である。 ~get~ の場合とちがって状態を保持する変数（この場合では ~str-state~ ）が線形に使用されているところ、状態を読むことができているところ、状態を書き換えることができている（かのように見える）ところに注目されたい。こうして余計なコピーを引き起こすことなく状態を利用することが可能になる。

なんにせよ、原理的に上記のようにして状態管理が可能であるなら、あとは適当な構文糖衣を用意してやるだけの話である。それゆえ状態にともなうコピー祭りは回避できる。状態管理、くらりんり、君に聞こえるのは僕が知らない声になっていく。

**** 対応するmalloc/freeの打ち消し
3つ目。静的にリソース管理が実現されるという点についてあらためて考えてみる。当たり前のことではあるが、このときは、コンパイルが終了した時点で、どこにmalloc/freeが挿入されるか、またmallocにおいて確保するべきメモリ領域のサイズはいくらか、といった情報がすでに得られていることになる。であるならば、コンパイル結果には、たとえば次のような疑似コードに相当するようなLLVMコードが含まれうることになる：
#+begin_src txt
a := malloc(SIZE);
(...)
free(a);
b := malloc(SIZE);
(...)
free(b);
#+end_src
このとき、 ~a~ と ~b~ との ~malloc~ ではどちらも同サイズのメモリ領域を利用するのだから、不要になった ~a~ の領域を ~b~ で使い回すことができるはずである。つまり、上記のコードを
#+begin_src txt
a := malloc(SIZE);
(...)
b := a;
(...)
free(b);
#+end_src
に書き換えられるはずである。で、それは実際に可能で、この最適化処理は今回実装した言語のなかに組み込んである。

これだけだとちょっとそっけないので、一言コメントを添えてみる。ベースの言語がλ計算ベースであることを思い出してもらうと、この言語に対し、コンパイル時点で簡約（インライン展開）をかなりゴリゴリと適用していけることが想像できると思う。でもって、インライン展開をおこなえばおこなうほどに、ひとまとまりのコード片（λ抽象の中身）のサイズは大きくなっていくはずで、ということは上記のような、サイズのそろったmalloc/freeのペアは見つかりやすくなっていく。というわけで、こちらの最適化はインライン展開とも相性のよいものとなっている。

**** 性能についての総括
それで、これらの最適化が現実にどれくらいうまく機能するのか、まともな性能を期待できるのかだけど、正直言ってわからない。個人的には、上記のようにやれば線形λ計算で書ける範囲って案外広いんじゃないか、案外いけるんじゃないか、って気がしていたりもするのだが、こんなのはただの想像であって、どんなものによっても支えられておらず、どこにもたどりつかない。実際にフルの言語にしてプロファイルもとれるようにして、などとしてみたいところではあるが、即物的なあらゆるものが足りない。

そういえば、関連する話として、マルチスレッドな挙動を考えたときにどうなるのかも気になるところではある。変数の書き換えを上記のようなshadowingでやるかぎりにおいて、たぶん複数スレッドのあいだで状態を送ったり受け取ったりといったことはできなくなると思うんだけど、それがどれくらいしんどいのか。

Curry-Howard的な路線として、[[https://arxiv.org/abs/1802.00961][Gödelの公理などをもちいて複数スレッド間でデータを受け渡したりするような研究]]もあるみたいで、どうしても証明論的に状態を共有したいのであればこっちの路線を調べていくことになるのかもしれない（Gödelの公理ってのは \( (A \to B) \lor (B \to A) \) ってやつ）。しかし当該の論文における簡約はかなり込み入ったものとなっていて、まだそのままではちょっとあつかいづらいように見える。どうしたもんでしょ。現実的には、怪しげな定数を入れてやってそっちにマルチスレッドな挙動のためのズルを詰め込むとか、そういう路線になるのだろうか。よくわからない。

# *** これと似ていそうな話
# 話を変えよう。私が知っている範囲で本稿にいちばん近い既存研究はたぶんTolmachの[[https://www.cs.tufts.edu/~nr/cs257/archive/andrew-tolmach/tag-free-gc-as-published.pdf][Tag-free Garbage Collection Using Explicit Type Parameters]]だと思う。ここでは、Tolmachの研究を紹介したうえで、似ているところとそうでないところとを簡単にみてみる。

# **** Tag-free Garbage Collection Using Explicit Type Parametersの紹介
# まずもって、一般に、GCにおいてはデータ構造がどのような形をしているのかを知る必要がある。リストでも構造体でもなんでもいいが、そうした特定のデータのうちのある部分が他のどこからも参照されていないということをチェックするためには、そもそもその「特定のデータ」とやらの中身を辿ることができないといけない。そこがわからないと、データの依存関係がわからず、あるデータが不要になっているのかどうかを判定することができない。

# というわけで、伝統的なGCにおいては、文字列とかペアとかに対し、追加の情報としてデータの構造を調べるためのタグが付与される。たとえば
# #+begin_src txt
# ("foo", "bar", ("buz", "qux"))
# #+end_src
# のようなデータ構造があるとしたら、これはメモリ上では
# #+begin_src txt
# pair1 := [tag1, (pointer to "foo"), (pointer to "bar"), (pointer to pair2)]
# pair2 := [tag2, (pointer to "buz"), (pointer to "qux")]
# #+end_src
# といった具合で、タグ情報を付与したものとして保持される。この ~tag1~ とか ~tag2~ の部分には、たとえば、このtupleがいくつの要素から構成されるものであるのか、などの情報が記録される。ガベージコレクタは実行時にこの部分の情報を利用してデータ構造を辿っていくことになる。

# なるほど確かにこれはガベージコレクタの実装を可能にするにあたっての素直な手法ではある。だがTolmachにしたがって言えば、こうしたタグは、

# 1. もし削除することができればメモリ空間を大幅に節約することができるものである
# 2. 目下のデータの「自然な」表現から現在あつかっているデータを遠ざけるものである

# という点において、可能であれば削除することが望ましい。

# Tolmachはこうしたタグを使用しないGCを型情報を利用して実現する。つまり、上記の ~tag1~ とか ~tag2~ といった部分に格納されていたぶんの情報を、型のほうにうつすのである。より具体的には、

# 1. System F相当の言語（HaskellとかOCamlみたいな言語）をユーザが書く
# 2. 依存型チックに、型がふつうのtermとなっているような言語へとベースの言語を変換する
# 3. termとして利用できるようになった型をGCのための情報として利用する

# といった具合で処理をおこなう。タグの情報は型のほうへと移り、これによって、タグを利用することなしにGCが実現される。ガベージコレクタは型とtermとを同時に読みながらデータ構造をたどっていくことになる。

# 論文ではこれらの実装方針についての詳細が与えられたうえでパフォーマンスの評価がおこなわれ、タグのかわりに型情報を利用することのオーバーヘッドは "acceptably small" であることが主張される。

# **** 比べてみましょう
# で、藁人形論法かもしれないが、もし「この記事でやってることってだいたいTolmachのやつと一緒じゃねえの？」という思いが浮かびあがってくるとしたら、それはおそらく、Tolmachの研究と本稿の双方がともに、termとして利用できるようになった型をリソース管理のために利用しているからだと思う。なるほどたしかに、Tolmachの研究においてはベースの言語が依存型でないためこれを依存型チックな（ちゃんと言うと2階の）λ計算へと変換する処理が絡んではいるものの、その変換を噛ませた後のことを考えれば、「通常eraseされるものであるところの型をリソース管理に利用してやれるのではないか」というアイデアにおいては共通している。

# けれども両者のあいだには大きな、たぶん決定的な差異もあって、つまりリソース管理方式が動的か静的かである。とくに、静的なメモリ管理を支えているη展開の発想、証明論の言葉からリソースを管理してやれるのではないかという発想はこちらにだけあるものである。Tolmachの手法をとるかぎりにおいて、型はあくまでその型をもつtermの構造を表現するようなタグであり、それゆえそのタグを利用するような別の存在者が必要となる。他方で今回の手法ではまさに型によってリソースの制御がおこなわれるのであり、ここにおいて両者は質的に異なる。

# あるいはもっと動機のほうに注目するなら、Tolmachの手法がもともと既存のGCに対する不満から出発しているのに対し、本稿の手法はつまるところ証明論的な興味に動かされるうちに結果として出てきたものである。つまり両者はそもそもからして目指している方向が違うのであり、型をリソース管理のために利用するという共通点はそれぞれが結果へと向かう途中でのほとんど偶然の邂逅であるとさえ言ってしまえるかもしれない。言いすぎかもしれんが。

# あ、差異といえば、Tolmachのほうでだけパフォーマンスがきちんと評価されていたり議論の細部が詰められていたりするという意味で、歴然としたクオリティ差もあるのだった。それについてはうなずくしかない。
# # えらすぎる。いや、どちらかといえば私がえらくないだけだが。

*** その他のあれこれ
落ち穂拾い。やってないことなどについて。

**** 安全性の話
まず、記事冒頭にも書いたが、この手法がなんらかの意味において正当、あるいは安全であることの証明はまだない。時間的資源とかのあれこれを天秤にかけた結果である。

安全性についてひとつふれておくべきことがあるなら、Russellのパラドックスにかかわるものだろうか。今回の論理体系は ~Type : Type~ を認めており（あるいはまた不動点演算子を含んでおり）、それゆえもちろん矛盾している。つまり任意の型 ~A~ に対し、その型をもつような証明項 ~e~ が存在する。他方で本稿のリソース管理システムは型/命題ありきのものとなっているのだった。であるならば、この矛盾を利用しておかしな型をつくってやればリソース管理システムを破壊できるのではないか、という疑問がありうる。

が、実際にやってみるとわかるが、これはたんに ~e~ の実行が無限ループに陥るだけの話である。 ~Type : Type~ を認めているからといって、たとえば突然 ~"hello" : int~ のような型判断が通るようになったりはしない。  ~Type : Type~ や ~fix~ を利用することで任意の命題 ~A~ に対してその証明 ~e : A~ を構成するとき、この ~e~ はなお一定のパターンにしたがっているのであり、いわばこうした体系は秩序をもって矛盾しているのである。……例によって証明はないが。

あ、もちろん無限ループからスタックオーバーフローを経由してセグフォを引き起こすことはできる。Cとかと同じように。

**** 表示的意味論どこ？
詳しい人が見ればゼロコンマ2秒で分かる通り、本稿の話は統語論というか証明論にかなりかたよったものであって、表示的意味論の話がまったく含まれていない。実際のところ、型を特定の関数へと変更するというのは結構おもしろい気がしていて、その圏論的意味論からみたふるまいも気になるところではあるのだが、残念なことにいまのところ私は依存型の圏論的意味論をよく知らない。「無敵のfibrationってやつでなんとかしてくださいよ〜」くらいの知識しかない。つまりなにも知らないということである。

**** 理論的整備がまだまだですねという話
上の話とも関連するが、まあ理論的整備がぜんぜんである。祈りに近い。正しくブログ記事という感じではあるが。ややテクニカルな話をすると、今回つくったコンパイラがやっていることは、おおむね

1. Calculus of Constructionsとよばれる体系からスタートする（ユーザがソースコードに書くやつはこれ）
2. 当該の体系をCall-By-Push-Value (CBPV)の依存型バージョンと変換する
3. dependent CBPVに対してクロージャ変換をおこなってすべてのλ抽象をclosedにする
4. 型の計算論的解釈によってリソースの線形化処理をおこなう
5. 得られた情報を利用しつつ普通のコンパイラと同じようなノリで仮想マシンコードを生成

という処理の組み合わせとして理解できるのだが、ここでのそれぞれの変換を具体的に書き下すという作業をおこなっていない。なんなら依存型バージョンのCBPVがぶっこわれていないことをチェックしてすらいない。一般に言って、いけそうな思い付きというのはきちんと定式化してやるとたいていどこかしらバグっているものであり、それは今回の話についてもむろん例外ではあるまい。どっかしらぶっ壊れているかもしれない[fn:eff-in-type]。

# **** dependent inductive type
# データ型についてちょっと付言しておく。Haskellで言うところの代数的データ型のようなものは今回の言語にも含まれている。つまり、listであるとか構文木であるとかをHaskellの ~data~ みたいなノリで書ける。けれども、dependentなinductive typeは入っていない。なのでCoqとかAgdaとかLeanとかのものよりも今回の言語のそれは真に弱い。依存型の言語、って言ってるわりに。

# 内部的にはChurch encodingを用いることでこうした代数的データ型をλ抽象に帰着しており、それゆえリソース管理をしつつGADTを利用できるようになっているわけだけど、これをどう一般化するかは謎である。

**** 名前のこと
どうでもいいが（と書くとき本当にどうでもいいと思っていることがはたしてどれくらいあるのだろうか）、せっかくなので今回書いた言語の名前について一言添えておく。今回の言語の名前は "neut" としてみたわけだが、私は別に、たとえばこの言語はなんらかの意味において中立的なものであるのだぞとか、そうした思いを持っているわけではない。というか「自然演繹大好き～♡」って立場を採用している時点でもう思いっきりopinionatedだし。むしろ、これはたんに実装の内部からきた名前である。

上でも軽くふれたとおり、今回の言語のコンパイルの過程においては、直観主義のλ計算 (Calculus of Constructions) をCall-By-Push-Value (CBPV) という計算体系へと変換する処理が含まれている。CBPVと普通の体系との差異は、前者において型が大きく2種類に分かれるという点に求められる。より具体的には、CPBVにおいては、型が「値の型」と「計算の型」に分かれる。値のほうはふつうpositiveであるとされ、また計算のほうはふつうnegativeであるとされる。つまり言語に極性 (polarity) が入っている。たとえばCBPVにおける「\( \to \)」の導入則はつぎのようになる：

\[
\begin{prooftree}
  \AxiomC{\( \Gamma, x : P \vdash e : N \)}
  \UnaryInfC{\( \Gamma \vdash \lambda x.e : P \to N \)}
\end{prooftree}
\]

ここで \( P \) というのはpositiveな型であり、 \( N \) というのはnegativeな型である。λ抽象の引数はつねにpositiveでなければならず、また関数本体はつねにnegativeでなければならない、といった具合で、特に \( P \to N \) それ自体はnegativeな型であり、ゆえにたとえばλ抽象をそのまま別のλ抽象に引数として与えることができなくなっていたりする。

線形論理がリソースについて論理をより詳しく分析するものであると言うなら、CBPVは簡約について論理をより詳しく分析するものであると言ってみてもよいかもしれない（ちょっと乱暴かもしれないが）。もうすこし詳しいことについては[[https://www.cs.cmu.edu/~fp/courses/15816-f16/lectures/21-cbpv.pdf][このへん]]をみてもらえればと思う。当該の講義資料は自然演繹についての基本的なことを知っていれば読めるはずである。CBPVを作った/発見した人であるところの[[https://www.cs.bham.ac.uk/~pbl/papers/thesisqmwphd.pdf][Levy本人による博士論文]]はより詳細であるが、いきなりだとなかなか近寄りがたいかもしれない。

なんにせよ、ポイントは、コンパイルの過程においてユーザの入力がpositiveな断片とnegativeな断片とに極化されるというところである。逆に言えば、ユーザが書いたプログラムにはまだ極性が入っておらず、そのかぎりにおいてneutralである。ユーザがソースコードに書くのはneutralな証明項である。というわけで、ちょうどテキストファイルに書かれるのがテキストで、その拡張子が ".txt" となるように、neutral termを書くファイルの拡張子は ".neut" とすることにし、これをそのまま言語の名前として用いることにしてみた。それだけの話でした。

** 跋
対ありでした〜

[fn:depcls] クロージャ変換のこの3要素への拡張は本質的にはただの存在量化である。親しみ深い存在量化は、 ~x + 1 = 0~ のような自由変数をもった主張から始めて、ここから ~exists (x : Integer). x + 1 = 0~ のような命題をつくり、いわば変数 ~x~ の部分を匿名化するものであった。上でやっているのも同じことで、つまり、もともとクロージャ
#+begin_src txt
({自由変数のあつまり},
 λ (もとの引数, env).
   let (自由変数だったものたちの名前) := env in
   {もとのコード})
#+end_src
の型（= 命題）は
#+begin_src txt
(A1, ..., An) * {...}
#+end_src
であるわけだが、この第1成分のほう、自由変数の具体的な型のありようを存在量化で匿名化して、
#+begin_src txt
Sigma (A : Type). A * {...}
#+end_src
としているのがここでの変換である。この変換によって、もともと型のほうに入っていた ~(A1, ..., An)~ の情報がクロージャの第1成分というterm側に降りてきているところがポイントである。

ところで、このような、クロージャを3成分に拡張する手法は特に新しいものではないらしい。実際、これが本題というわけではないが、[[https://github.com/u2zv1wx/neut/issues/1][githubリポジトリのissue]]で[[https://www.ccs.neu.edu/home/amal/papers/closconvcc.pdf][紹介された論文]]でも同じようなことをやっているとのことであり（まだ読んでいないが）、また簡単に調べてみただけでも、[[https://sv.c.titech.ac.jp/minamide/papers/popl96.pdf][1996年時点ですでに似た話がある]]ように見える。というわけで、いろいろ困ったことになるのは避けたいので、クロージャのこの3要素による変換について、本稿は特にこれといってオリジナリティを主張しない。

[fn:closedchain] あるいは、ここで次のような疑問を抱くかもしれない。つまり、型のなかに自由変数が含まれていたらどうするのか、という疑問である。結論から言うと、こうした状況には自由変数の概念を拡張することによって対応する。つまり、自由変数の型の中に含まれる自由変数もまた、もとのtermの自由変数として数え入れるのである。たとえば、
#+begin_src txt
λ (A : Type). λ (x : A -> int). (x, 100)
#+end_src
のようなtermがあったとする。このとき、 ~(x, 100)~ の自由変数は、普通はたんに ~x~ だけであるとされる。が、ここでは、 ~x~ の型であるところの ~A -> int~ が自由変数として ~A~ を含んでいるので、この ~A~ もまた自由変数として数え入れられることになる。他方、 ~A~ の型であるところの ~Type~ には自由変数は含まれないので、けっきょく、 ~(x, 100)~ の自由変数は ~A, x~ である、となる。このようにすることで、自由変数をコピーするための型の情報がすべてクロージャの第1成分に入ってくることになる。これによってクロージャがうまくコピーできるようになる。

[fn:eff-in-type] そういえば、型に副作用があったらどうするのか、という疑問がありうる。これについては選択肢は少なくとも2つある：

1. 言語を純粋にしてそもそも副作用が絡んでいるときには型検査を通過しないようにする
2. 型検査は通過させて動作を未定義にする

前者の路線では、たとえば ~print~ の型を ~string -> io (string * top)~ などとしておく。こうしてやると、 ~print~ を利用しているような型の型は ~Type~ ではなく ~IO Type~ となってくれるわけで、それゆえ ~A : IO Type~ となるとき ~A~ は型ではなくなる。というわけでこうした ~A~ をたとえば関数の型の内部で ~A -> int~ のようにして使用することはできなくなり、秩序が得られる。

後者の路線では「型にわけのわからんものを書いたお前が悪い」の一言ですべてを終了させる。ちなみに今回の言語ではこちらの路線を採用してある。

[fn:modal] ややテクニカルな注釈を添えておく。線形論理からスタートして直観主義論理の表現能力を得ようと思ったなら、まず考えつくのはexponentialの様相を使うことだろうが、こちらの方針ではうまくメモリを静的に管理することができない（と思う）。というのは、S4の様相と同様の仕方でこのexponentialの様相を入れ、さらにその様相をもつもの（つまり ~!A~ という形の型を持つもの）に対してweakening / contractionを認めたとき、当該の論理体系はけっきょく ~!A~ という形の型だけが出現するようなフラグメントとして実質的に直観主義論理をそのまま含むことになってしまうからである。最初の「直観主義論理ベースな計算体系のメモリってどうやって管理するの？」の問題に戻ってきてしまう。

[fn:judgmental] ここでの話は、最後の与太話を除いて[[https://www.cs.cmu.edu/~fp/papers/mscs00.pdf][こちらの論文]]をベースにしたものになっている。

# なお、当該の論文は局所完全性を除去則についての述語として定めているが、本稿では論理結合子についてのものとして定めてある。これは「こっちのほうが私にとってなんとなくしっくりくるから」くらいの理由にすぎず、どちらで定めようが特に話は変わらない。

[fn:adj] もっと言うと、[[https://math.stackexchange.com/questions/1633210/is-there-a-connection-between-local-soundness-and-completeness-in-proof-theory][両者は随伴におけるtriangle identitiesのそれぞれに対応している]]ようである。

[fn:reginf] 当該のコンパイラにおいては、実際には既存コードをなるべく効率的にコンパイルするべくGCが同時に利用されていたりする。が、これはあくまでひとつの最適化であると理解しておけばよかろう。

[fn:asm] もうすこし正確には、除去則の結論を、導入則の前提、および除去則の追加の仮定から証明するという操作である。つまり、たとえば \( \to \) の除去則では

\[
\begin{prooftree}
  \AxiomC{\( \Gamma \vdash A \to B \)}
  \AxiomC{\( \Gamma \vdash A \)}
  \RightLabel{\( (\to_{\mathsf{e}}) \)}
  \BinaryInfC{\( \Gamma \vdash B \)}
\end{prooftree}
\]

のように \( A \to B \) と \( A \) が前提としてとられるが、これでいうところの \( A \) が「除去則の追加の仮定」である。「\( \land \)」の例ではここが0個になっている。

[fn:linear] もしかすると、この制限はなんだか突然どこからともなく降ってきた恣意的なものに見えるかもしれない。が、これは実際には直観主義論理を考えるかわりに線形論理で考えてみるという「よくある」分析に沿ったものとなっている。こういう分析について書いてある文献としては照井先生の[[http://www.kurims.kyoto-u.ac.jp/~terui/birth.pdf][これ]]が個人的におすすめ。
